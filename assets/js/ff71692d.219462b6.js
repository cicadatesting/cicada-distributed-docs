"use strict";(self.webpackChunkcicada_distributed_docs=self.webpackChunkcicada_distributed_docs||[]).push([[986],{3905:function(e,n,t){t.d(n,{Zo:function(){return u},kt:function(){return f}});var o=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,r=function(e,n){if(null==e)return{};var t,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=o.createContext({}),c=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},u=function(e){var n=c(e.components);return o.createElement(l.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},p=o.forwardRef((function(e,n){var t=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(t),f=r,m=p["".concat(l,".").concat(f)]||p[f]||d[f]||a;return t?o.createElement(m,i(i({ref:n},u),{},{components:t})):o.createElement(m,i({ref:n},u))}));function f(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=t.length,i=new Array(a);i[0]=p;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var c=2;c<a;c++)i[c]=t[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}p.displayName="MDXCreateElement"},178:function(e,n,t){t.r(n),t.d(n,{assets:function(){return u},contentTitle:function(){return l},default:function(){return f},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return d}});var o=t(7462),r=t(3366),a=(t(7294),t(3905)),i=["components"],s={id:"load-models",title:"Load Models"},l=void 0,c={unversionedId:"reference/load-models",id:"reference/load-models",title:"Load Models",description:"N Iterations",source:"@site/docs/reference/load-models.md",sourceDirName:"reference",slug:"/reference/load-models",permalink:"/cicada-distributed-docs/docs/reference/load-models",editUrl:"https://github.com/cicadatesting/cicada-distributed-docs/edit/main/docs/reference/load-models.md",tags:[],version:"current",frontMatter:{id:"load-models",title:"Load Models"},sidebar:"tutorialSidebar",previous:{title:"Decorators",permalink:"/cicada-distributed-docs/docs/reference/decorators"},next:{title:"Backend and Console Metrics",permalink:"/cicada-distributed-docs/docs/reference/backend-console-metrics"}},u={},d=[{value:"N Iterations",id:"n-iterations",level:2},{value:"Run Scenario Once",id:"run-scenario-once",level:2},{value:"N Seconds",id:"n-seconds",level:2},{value:"N Users Ramping",id:"n-users-ramping",level:2},{value:"Ramp Users To Threshold",id:"ramp-users-to-threshold",level:2}],p={toc:d};function f(e){var n=e.components,t=(0,r.Z)(e,i);return(0,a.kt)("wrapper",(0,o.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"n-iterations"},"N Iterations"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from cicadad.core.scenario import n_iterations\n")),(0,a.kt)("p",null,"Makes user group run test function a limited number of times."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def n_iterations(\n    iterations: int,\n    users: int,\n    wait_period: int = 1,\n    timeout: Optional[int] = 15,\n    skip_scaledown: bool = False,\n):\n    """Creates a load model where a pool of users is called n times\n\n    Args:\n        iterations (int): Number of shared iterations for users to run\n        users (int): Size of user pool\n        wait_period (int, optional): Time in seconds to between polling for results. Defaults to 1.\n        timeout (Optional[int], optional): Time in seconds for scenario to complete before failing. Defaults to 15.\n        skip_scaledown (bool): Skip scaledown of users after running load function\n    """\n')),(0,a.kt)("h2",{id:"run-scenario-once"},"Run Scenario Once"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from cicadad.core.scenario import run_scenario_once\n")),(0,a.kt)("p",null,"Runs the scenario with one user only one time. This load model is enabled by\ndefault."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def run_scenario_once(wait_period: int = 1, timeout: Optional[int] = 15):\n    """Runs scenario one time with one user\n\n    Args:\n        wait_period (int, optional): Time in seconds to wait before polling for results. Defaults to 1.\n        timeout (int, optional): Time in seconds to wait for scenario to complete before failing. Defaults to 15.\n\n    Returns:\n        Callable: Closure for configured load model\n')),(0,a.kt)("h2",{id:"n-seconds"},"N Seconds"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from cicadad.core.scenario import n_seconds\n")),(0,a.kt)("p",null,"Runs user group for a specified duration."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def n_seconds(\n    seconds: int,\n    users: int,\n    wait_period: int = 1,\n    skip_scaledown=False,\n):\n    """Run the scenario for a specified duration. Should be used with the\n    \'while_alive\' user loop\n\n    Args:\n        seconds (int): Number of seconds to run scenario\n        users (int): Number of users to start for scenario\n        wait_period (int, optional): Time in seconds to wait before polling for results. Defaults to 1.\n        skip_scaledown (bool): Skip scaledown of users after running load function\n    """\n')),(0,a.kt)("h2",{id:"n-users-ramping"},"N Users Ramping"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from cicadad.core.scenario import n_users_ramping\n")),(0,a.kt)("p",null,"Scales to specified number of users over time."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def n_users_ramping(\n    seconds: int,\n    target_users: int,\n    wait_period: int = 1,\n    skip_scaledown: bool = True,\n):\n    """Scale users to target over the duration of the time specified. Use this\n    to scale users smoothly.\n\n    Args:\n        seconds (int): Amount of time to spend ramping users\n        target_users (int): Number of users to ramp to.\n        wait_period (int, optional): Time in seconds to wait between scaling batch of users. Defaults to 1.\n        skip_scaledown (bool, optional): Do not scale down users after load model completes. Defaults to True.\n    """\n')),(0,a.kt)("h2",{id:"ramp-users-to-threshold"},"Ramp Users To Threshold"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from cicadad.core.scenario import ramp_users_to_threshold\n")),(0,a.kt)("p",null,"Gradually increases number of users until a threshold is met."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def ramp_users_to_threshold(\n    initial_users: int,\n    threshold_fn: Callable[[Any], bool],\n    next_users_fn: Callable[[int], int] = lambda n: n + 10,\n    update_aggregate: Callable[[int, Any], Any] = lambda n, agg: f"Users: {n}",\n    period_duration: int = 30,\n    period_limit: Optional[int] = None,\n    wait_period: int = 1,\n    skip_scaledown: bool = False,\n):\n    """Increase number of users in scenario until a threshold based on the\n    aggregated results is reached. Update aggregate with number of users determined\n    by scenario.\n\n    Args:\n        initial_users (int): Users to start stage with.\n        threshold_fn (Callable[[Any], bool]): Checks aggregate and returns True if threshold reached.\n        next_users_fn (Callable[[int], int]): Scale number of users given current number of users.\n        update_aggregate (Callable[[int, Any], Any], optional): Update scenario aggregate with result of load model.\n        period_duration (int, optional): Time in seconds to wait before scaling test. Defaults to 30.\n        period_limit (Optional[int], optional): Amount of scaling events before stopping stage. Defaults to None.\n        wait_period (int, optional): Time in seconds to wait before polling for results. Defaults to 1.\n        skip_scaledown (bool): Skip scaledown of users after running load function\n    """\n')))}f.isMDXComponent=!0}}]);